{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP-598 Lecture 2: Linear Regression\n",
    "\n",
    "In general for superviesed learning we have a dataset of training examples $x_i$: $x_i = (x_{i1}, x_{i2}, \\ldots, x_{in}, y_i)$. Here we have $m$ features in each of our training examples. Given such a dataset of $X\\times Y$ we want $f:X\\longrightarrow Y$, where $f$ is the hypothesis function.\n",
    "\n",
    "## Variable Types\n",
    "\n",
    "1. Ordinal - no metric relation between values, allows us ranking / ordering\n",
    "2. Qualitative - Categorical labels for a value.\n",
    "3. Quantitative - A continous real value.\n",
    "\n",
    "## The i.i.d. assumption\n",
    "1. all rows of dataset are independent (or freshly sampled)\n",
    "2. all rows of dataset are identical (they are from the same underlying distribution)\n",
    "\n",
    "- these assumptions are made in supervised learning and sometimes in unsupervised learning but not inreinforcement learning.\n",
    "- this is important because it allows us to assume that errors are independent. \n",
    "\n",
    "## Risk Minimization\n",
    "Given some measure of error or error function $L_s(f)$ that quantifies the errors made by $f$ on a set $S$, we want:\n",
    "$$ERM_F (S) = \\arg\\min_{f\\in F} L_s(f) $$\n",
    "\n",
    "Where $F$ is a class of functions known as the *Hypothesis Class* (eg: lines, parabolas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Linear Functions\n",
    "\n",
    "### Representation\n",
    "\n",
    "Given some weights $w$ and feature set $X$, we propose the following hypothesis function: $f_w (X) = w_0 + w_1 x_1 + \\ldots + w_m x_m$. How can we handle $w_0$? We simply add an extra feature $x_0 := 1$ which is known as the bias term. We can now simplify:\n",
    "\n",
    "$$f_w (X) = \\Sigma_{j=1}^{m} w_jx_j$$\n",
    "\n",
    "We can write this in matrix form: $f_w(X) = Xw$, where $X$ has dimensions $n\\times m$ and $w$ and dimensions $m \\times 1$\n",
    "\n",
    "### Evaluating the Error in $w$\n",
    "\n",
    "$$ Err(w) = \\Sigma_{i=1}^n (y_i - w^Tx_i)^2 $$\n",
    "\n",
    "Rewritten in matrix notation:\n",
    "\n",
    "$$Err(w) = (Y-Xw)^T(Y-Xw)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(X,Y, W):\n",
    "    A = Y-X*W\n",
    "    return (A.T * A)[0]\n",
    "\n",
    "#x_validate = np.matrix( [ np.ones(50) ,np.linspace(0,1,50) ] ).T\n",
    "#y_validate = np.matrix( np.linspace(0,1,50) + 1 ).T\n",
    "#mean_squared_error(x_validate, y_validate, np.matrix([[1],[1]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizing the Error (Optimization)\n",
    "\n",
    "We take the derivative wrto $w$ and equate to $0$:\n",
    "$$\\frac{\\delta Err(w)}{\\delta w} = -2 X^T (Y-Xw) = 0$$\n",
    "$$\\implies X^TY = X^TXw \\implies \\bar{w} = (X^TX)^{-1}(X^TY)$$\n",
    "The weights obtained are estimates and they show how important certain features are relative to each other. the computational cost of this algorithm is dominated by the inversion process and it takes $O(m^3)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.matrix( [ 0.86, 0.09, -0.85 , 0.87, -0.44, -0.43, -1.10 , 0.40, -0.96 , 0.17 ] ).T\n",
    "labels = np.matrix( [ 2.49 , 0.83, -0.25 , 3.10 , 0.87 , 0.02, -0.12 , 1.81, -0.83,  0.43 ] ).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first pad the data with ones to add the bias term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bias_term(data):\n",
    "    bias_term = np.ones( ( data.shape[0] , 1 ) )\n",
    "    return np.matrix( np.append(bias_term, data, axis =1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = add_bias_term(data) , labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us try term by term to see if we calculate the right answer, then we will encapsulate it in another function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 10.    ,  -1.39  ],\n",
       "        [ -1.39  ,   4.9261]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.35  ],\n",
       "        [ 6.4601]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T * Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.10408228,  0.02936895],\n",
       "        [ 0.02936895,  0.2112874 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X.T * X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.05881341],\n",
       "        [ 1.61016842]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X.T * X)  * (X.T * Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now encapsulate it in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_fit = add_bias_term(np.matrix(np.linspace(-1.5,1.5,100)).T)*np.linalg.inv(X.T * X)  * (X.T * Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1069d4a10>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4v8B4Ggne3rA/34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069dd9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data, Y, 'x')\n",
    "\n",
    "plt.plot(np.linspace(-1.5,1.5,100), line_fit , 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty good! Now let's encapsulate it for future use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(X, Y):\n",
    "    return np.linalg.inv(X.T * X)  * (X.T * Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_hypothesis(weights):\n",
    "    \"\"\"\n",
    "        returns a function that can be evaluated using X to obtain y\n",
    "    \"\"\"\n",
    "    def h(X):\n",
    "        \n",
    "        return np.array(add_bias_term(X) * weights)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_estimates = least_squares(X, Y)\n",
    "f_estimate = linear_hypothesis(w_estimates)\n",
    "y_estimates = f_estimate( np.matrix(np.linspace(-1.5, 1.5, 100)).T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.24015903]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(X,Y,w_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "Note that the gradient of the error is the vector indicating the direction to the minimum. We can make steps toward that minimum.\n",
    "See following pseudocode:\n",
    "\n",
    "1. Randomly initialize a weight vector $w_0$\n",
    "2. For (k=1:N)\n",
    "    $$w_{k+1} = w_k - \\alpha_k \\frac{\\delta Err(w_k)}{\\delta w_k}$$\n",
    "3. We end when $|w_{k+1} - w_{k}| < \\epsilon$\n",
    "\n",
    "Convergence depends on the learning rate, $\\alpha_k>0$ for iteration $k$. If it is too large, the algorithim will oscillate forever, if it's too small, it will take too long to converge.\n",
    "\n",
    "We can pick $\\alpha$ based on some theoretical criterion picked dynamically by using the **Robbins-Monroe Conditions** but in most cases it is kept constant.\n",
    "\n",
    "\n",
    "Below we attempt to implement this algorithm using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_of_squared_error(X,Y,W):\n",
    "    return -2 * X.T * (Y - X*W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y, error_function=derivative_of_squared_error, max_iterations=200, alpha=0.5, return_ws=False):\n",
    "    number_of_weights = X.shape[1]\n",
    "    w = np.matrix(np.random.random(size=number_of_weights)).T\n",
    "    w_iterated = [w]\n",
    "    for k in range(max_iterations):\n",
    "        w_new = w - alpha * error_function(X,Y,w) # calculate new w.\n",
    "        w_iterated.append(w_new)\n",
    "        w = w_new\n",
    "    if return_ws:\n",
    "        return w, w_iterated\n",
    "    else:\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights=gradient_descent(X,Y,max_iterations=10,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.05817746],\n",
       "        [ 1.60768421]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
