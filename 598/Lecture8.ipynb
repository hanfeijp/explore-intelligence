{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 598 - Lecture 8 Decision Trees\n",
    "\n",
    "- Sometimes linear decision boundaries are not expressive enough we want to create a more complex rule set to model our data.\n",
    "- Dataset can have numerical information as well as non-numerical (text, categorical, binary)\n",
    "- Algorithm provides some rules that are human comprehendable.\n",
    "\n",
    "*Example of a deicison rule:* If texture > a and perimeter > b then \"Reccurence\"\n",
    "\n",
    "## Interpretation: Nodes\n",
    "Nodes represent a paritioning of the input feature space:\n",
    "1. Internal nodes are tests on the values of different features (or a decision rule)\n",
    "2. Leaf nodes contain examples that satisfy the rules of the nodes along the branch that is taken to reach it. Each leaf typically contains more than one example, each example can fall in only one leaf.\n",
    "\n",
    "## Procedure of Classification\n",
    "At every node, we conduct the test on the new example. We follow the appropriate branch of the tree. Once at a leaf, we will predict the class (if pure), the majority or sample from probabilities of the two classes.\n",
    "\n",
    "Our learning task here is to choose the tests at every node.\n",
    "\n",
    "**Na√Øve Approach:** \n",
    "We could enumerate all possible trees (assuming a finite number of tests) and evaluate the error. Select the one that produces the minimum error.\n",
    "\n",
    "This is problematic for obvious reasons: overfitting and computationally intensive.\n",
    "\n",
    "**Idea 1:** \n",
    "\n",
    "Given a set of labeled training instances:\n",
    "1. If all training instances have the same class, create a leaf with that class and exit.\n",
    "2. Pick the best test to split the data on according to some measure $G$.\n",
    "3. Split the training set according to the value of the outcome of the test.\n",
    "4. Recursively repeat steps 2 and 3 on each subset of the training data. \n",
    "\n",
    "Question 1: What is a \"good\" test?\n",
    "Question 2: How do we generate tests?\n",
    "Question 3: When do we stop building the tree such that we do not over fit the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory\n",
    "\n",
    "**Definition (Information Content)**\n",
    "\n",
    "Let $E$ be an event which occurs with probability $P(E)$. If we are told that $E$ has occured with certainty, then we have recieved $I(E)$ bits of intormation:\n",
    "\n",
    "$$I(E) = \\log_2 \\frac{1}{P(E)}$$\n",
    "\n",
    "Example: If you are observing the outcome of a dice roll, the roll provides $\\log_2 6$ bits of information.\n",
    "\n",
    "**Definition (Entropy)**\n",
    "\n",
    "Suppose we have an information source $S$ which emits symbols from an alphabet $\\{s_1, \\ldots, s_k\\}$ with probabilities $\\{ p_1, \\ldots, p_k \\}$. The entropy of $S$ is:\n",
    "\n",
    "$$H(S) = \\sum_{i=1}^k p_i I(s_i) = \\sum_{i=1}^k p_i \\log_2\\Big(\\frac{1}{p_i}\\Big) = - \\sum_{i=1}^k p_i\\log_2\\big(p_i\\big)$$\n",
    "\n",
    "We can rewrite this in terms of the probability distribution $P:~H(P) = \\sum_{i} p_i \\log_2 \\frac{1}{p_i}$\n",
    "\n",
    "Interpretation of $H$:\n",
    "1. Average amount of information per outcome.\n",
    "2. Average amount of \"surprise\" when observing an outcome.\n",
    "3. Uncertainty the observer has before seeing an outcome.\n",
    "4. Average number of bits needed to communicate an outcome. \n",
    "\n",
    "Given a binary dataset, $D$, of labels with $p$ positive samples and $n$ negative samples.\n",
    "$$H(D) = -\\frac{p}{p+n}\\log_2\\frac{p}{p+n} - \\frac{n}{p+n}\\log_2\\frac{n}{p+n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset $D$ that can be split into subsets via some tests, we want to know the which test, reduces the entropy the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def information_content(p):\n",
    "    \"\"\" Calculates the information content represented by the probability p \"\"\"\n",
    "    return np.log2(1/float(p))\n",
    "\n",
    "def entropy(P):\n",
    "    \"\"\" Calculates the Entropy of the (discrete) probability distribution P \"\"\"\n",
    "    return np.sum([ p * information_content(p) for p in P])\n",
    "\n",
    "def dataset_entropy(D):\n",
    "    \"\"\" Calculates the Entropy of a dataset\n",
    "        @params:\n",
    "        D: the dataset containing only the labels\n",
    "    \"\"\"\n",
    "    D = np.array(D)\n",
    "#     print D\n",
    "    labels = np.unique(D)\n",
    "#     print labels\n",
    "#     print(labels)\n",
    "    probabilities = np.zeros( len(labels) )\n",
    "    \n",
    "    # enumerate over all the labels and conduct some counting\n",
    "    for label_index, label in enumerate(labels):\n",
    "        probabilities[label_index] = np.sum(label == D)\n",
    "    \n",
    "    #divide by length of the dataset to get the probability of that class \n",
    "    probabilities = probabilities/float(len(D))\n",
    "#     print probabilities\n",
    "    # return the entropy of the probability distribution\n",
    "    return entropy(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Infofmration content of a coin flip is:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print('Infofmration content of a coin flip is:', information_content(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Entropy of a such a two class dataset:', 0.991076059838222)\n"
     ]
    }
   ],
   "source": [
    "D = ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A']\n",
    "print('Entropy of a such a two class dataset:', dataset_entropy(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Entropy of a such a equal two class dataset:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "D = ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']\n",
    "print('Entropy of a such a equal two class dataset:', dataset_entropy(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating Tests\n",
    "**Definition (Conditional Entropy)**\n",
    "\n",
    "$$H(y~|~x) = \\sum_{v} P(x=v) H(y~|~x=v)$$\n",
    "\n",
    "**Interpretation:** the expected number of bits needed to transmit y if both the emitter and reciever know the possible values of $x$ (but before they are told $x$'s specific value).\n",
    "\n",
    "\n",
    "Thus given a test $T$, a datapoint $d_i\\in D$ passes the test $T(d_i) = 1$ and fails it $T(d_i) = 0$, it divides the dataset into two sets: $D_{T=0}$ and $D_{T=1}. Entropy is given by:\n",
    "\n",
    "$$H(D~|~T) = P\\Big(T(d)=1)\\Big)H\\Big(D_{T=1}\\Big) + P\\Big(T(d)=0\\Big) H\\Big(D_{T=0}\\Big)$$\n",
    "\n",
    "Here $P(T(d))$ can be calculated by counting how many points $d$ pass the test or do not.\n",
    "\n",
    "**Definition (Information Gain)**\n",
    "In the context of a test, $T$. We can define information gain on a dataset $D$ as:\n",
    "$$IG(T) = H(D) - H(D~|~T)$$\n",
    "\n",
    "\n",
    "In classification we pick the test with the highest information gain.\n",
    "In regression we pick the test with the lowest mean-quared error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our metric for determining which tests are good.\n",
    "def information_gain(D, T):\n",
    "    \"\"\"\n",
    "        Calculates the information gain given by this test\n",
    "    \"\"\"    \n",
    "    D = np.array(D)\n",
    "    observations = D.T[-1].T\n",
    "    return dataset_entropy(observations) - test_entropy(D, T)\n",
    "\n",
    "def test_entropy(D, T):\n",
    "    \"\"\"\n",
    "        Calculates the entropy of a dataset D due to test T\n",
    "        @params:\n",
    "            D: dataset containing observations [(x_11,..., x_1m, y_1), ..., (x_n1, ..., x_nm, y_n)]\n",
    "            T: test to apply on the features\n",
    "    \"\"\"\n",
    "    # first vectorize the test.\n",
    "    D = np.array(D)\n",
    "    \n",
    "    #seperate observations and labels into their own arrays so that the test cannot access the label itself.\n",
    "    observations, labels = D.T[0:-1].T, D.T[-1].T\n",
    "\n",
    "    test_passed = np.apply_along_axis(T ,axis=1,arr=observations)\n",
    "\n",
    "    # whats the probability that a datapoint passes a test?\n",
    "    P_test_passed = np.sum(test_passed)/float(len(D))\n",
    "    P_test_failed = 1 - P_test_passed\n",
    "    \n",
    "    \n",
    "    # what are the labels that passed the test?\n",
    "    labels_test_passed = labels[ test_passed ]\n",
    "    labels_test_failed = labels[ np.invert(test_passed) ]\n",
    "    \n",
    "    # what is the entropy of the resulting datasets?\n",
    "    entropy_test_passed = dataset_entropy(labels_test_passed)\n",
    "    entropy_test_failed = dataset_entropy(labels_test_failed)\n",
    "\n",
    "    # return the entropy of the dataset given the test\n",
    "    return P_test_passed * entropy_test_passed + P_test_failed * entropy_test_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Information Gain due to test1, where resulting subsets have no impurities:', 1.0)\n",
      "('Information gain due to test2, where resulting subsets are diluted:', 0.048794940695398581)\n",
      "Since IG(test1)>IG(test2), test1 is a better test\n"
     ]
    }
   ],
   "source": [
    "D = [ (5,1,1,0,'A'), (5,1,0,1,'A'), (5,0,0,1,'A'), (5,0,0,0,'A'), (3,0,0,0,'B'), (3,1,0,0,'B'), (3,1,1,0,'B'), (3,1,1,1,'B') ]\n",
    "test = lambda d: int(d[0])==5\n",
    "print('Information Gain due to test1, where resulting subsets have no impurities:',information_gain(D, test))\n",
    "\n",
    "test2 = lambda d: int(d[1])==1\n",
    "print('Information gain due to test2, where resulting subsets are diluted:',information_gain(D, test2))\n",
    "print('Since IG(test1)>IG(test2), test1 is a better test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Tests\n",
    "\n",
    "We now need a way to generate tests and pick the best feature. We use the ID3 algorithm which goes through each unique value of each feature and generates a data split. Once the split has occured, we calculate the information gain by producing splits along a feature. We then pick the feature which causes the greatest information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first function, generates all the possible splits along a feature eaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_split(dataset, feature_index, continuous_decision=np.mean):\n",
    "    \"\"\"\n",
    "        generates a split according to the feature_index\n",
    "        @params:\n",
    "            dataset: the dataset \n",
    "            feature_index: the index of the feature we want to use\n",
    "            continous_decision: the decision boundary for a continous variable we want to pick\n",
    "    \"\"\"\n",
    "    dataset = np.array(dataset)\n",
    "    unique_values = np.unique(dataset[:, feature_index])\n",
    "    \n",
    "    #we now determine if these features are continous or not\n",
    "    try:\n",
    "        unique_values.astype(int)\n",
    "        type_is = 'int'\n",
    "    except ValueError as ve:\n",
    "        # these cannot be converted to ints \n",
    "        try:\n",
    "            unique_values = unique_values.astype(float)\n",
    "            type_is = 'float'\n",
    "        except ValueError as ve:\n",
    "            type_is = 'str'\n",
    "        #endtry\n",
    "    #endtry\n",
    "    if type_is in ['str', 'int']:\n",
    "        for val in unique_values:\n",
    "            yield dataset[dataset[:, feature_index] == val]\n",
    "    else:\n",
    "        # beta\n",
    "        print('Continous values decisions are in beta')\n",
    "        avg = continuous_decision(unique_values)\n",
    "        yield dataset[dataset[:,feature_index] >= avg ] \n",
    "        yield dataset[dataset[:,feature_index] < avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the information gain for a split conducted along each feature, it returns an array of information gains, we need to select the argument that maximizes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_split_feature(dataset, skip_features = []):\n",
    "    \"\"\"\n",
    "        determines which feature is best to split on.\n",
    "        @params:\n",
    "            dataset: the dataset\n",
    "            skip_features: skips the indicies of these features\n",
    "    \"\"\"\n",
    "    D = np.array(dataset)\n",
    "\n",
    "    observations, labels = D.T[0:-1].T, D.T[-1].T\n",
    "\n",
    "    n, m = D.shape\n",
    "    m -= 1 #accounting for the prediction column.\n",
    "#     print(m)\n",
    "#     print labels\n",
    "    H_D = dataset_entropy(labels)\n",
    "    gains = H_D * np.ones(m)\n",
    "    for i in xrange(m): #loop over all features\n",
    "        if i in skip_features: #skip features specified in an array\n",
    "            gains[i] = -np.Inf\n",
    "            continue\n",
    "        for subset in generate_split(D, i): #loop over all splits\n",
    "            # check if there is only one entry in the return\n",
    "            if len(subset.shape) == 1:\n",
    "                subset = np.array([subset])\n",
    "            gains[i] -= dataset_entropy(subset[:,-1])\n",
    "    return gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates a test on a feature column/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_test(feature_column, feature_index, continuous_decision=np.mean):\n",
    "    \"\"\"\n",
    "        Generates a test based on\n",
    "        @params:\n",
    "            feature_column, a slice of all the observations of this feature\n",
    "            feature_index, the index of this feature in the dataset\n",
    "            continous_decision, if the features are continous, the boundary to consider.\n",
    "    \"\"\"\n",
    "    unique_values = np.unique(feature_column)    \n",
    "    #we now determine if these features are continous or not\n",
    "    try:\n",
    "        unique_values.astype(int)\n",
    "        type_is = 'int'\n",
    "    except ValueError as ve:\n",
    "        # these cannot be converted to ints \n",
    "        try:\n",
    "            unique_values = unique_values.astype(float)\n",
    "            type_is = 'float'\n",
    "        except ValueError as ve:\n",
    "            type_is = 'str'\n",
    "        #endtry\n",
    "    #endtry\n",
    "#     print type_is\n",
    "    \n",
    "    if type_is in ['int', 'str']:\n",
    "        boundary = Counter(feature_column).most_common(1)[0][0]\n",
    "        # picks the most common element, hoping that this might seperate the data the best!\n",
    "        print('Picked feature',feature_index,' with boundary ',boundary)\n",
    "        return lambda d: d[feature_index] == boundary\n",
    "    else:\n",
    "        boundary = continuous_decision(unique_values)\n",
    "#         print boundary\n",
    "        return lambda d: d[feature_index] >= boundary\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the functions together we get a `generate_best_test` function which returns a tuple of feature_index and the test itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_best_test(dataset, skip_features=[], continuous_decision = np.mean):\n",
    "    \"\"\"\n",
    "        generates the best possible test given a dataset, skipping features specified\n",
    "        @params:\n",
    "            dataset: the dataset to conduct the split on\n",
    "            skip_features: the features to skip\n",
    "            continuous_decision: the decision boundary to which we use in our boundary selection.\n",
    "        @returns:\n",
    "            (feature_index, best_test)\n",
    "    \"\"\"\n",
    "    dataset = np.array(dataset)\n",
    "    feature_index = np.argmax(best_split_feature(dataset, skip_features=skip_features))\n",
    "    return feature_index, generate_test(dataset[:,feature_index], feature_index, continuous_decision=continuous_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Picked feature', 0, ' with boundary ', '3')\n",
      "(0, <function <lambda> at 0x10207a5f0>)\n"
     ]
    }
   ],
   "source": [
    "best_test = generate_best_test(D)\n",
    "print(best_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write some scaffolding for tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, L=None, R=None, details=None):\n",
    "        self.L = L\n",
    "        self.R = R\n",
    "        self.details = details\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.L == None and self.R == None\n",
    "        \n",
    "class Tree(object):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "    @staticmethod\n",
    "    def build_tree():\n",
    "        return Tree(Node())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecisionNode(Node):\n",
    "    def __init__(self, L=None, R=None, data_points=[], details=None, skip_features=[]):\n",
    "#         print('Building a decision node')\n",
    "#         print('Given datapoints:',data_points)\n",
    "\n",
    "        # base case 1 (only one data point)\n",
    "        if len(data_points) == 1:\n",
    "            self.L=None\n",
    "            self.R=None\n",
    "            self.data_points = data_points\n",
    "            self.label = data_points[-1]\n",
    "        else:\n",
    "                        \n",
    "            D = np.array(data_points)\n",
    "            # seperate into observaions and labels\n",
    "            observations, labels = D.T[:-1].T, D.T[-1].T\n",
    "            \n",
    "            # base case 2 (no more features to divide)\n",
    "            n,m = observations.shape\n",
    "            if m == len(skip_features):\n",
    "                self.label = Counter(labels).most_common(1)[0][0]\n",
    "                self.data_points = data_points\n",
    "                self.L=None\n",
    "                self.R=None\n",
    "            else:\n",
    "\n",
    "                if len(np.unique(labels))==1:\n",
    "                    # this is a pure node, stop recursing\n",
    "                    self.L= None\n",
    "                    self.R=None\n",
    "                    self.data_points = data_points\n",
    "                    self.label = np.unique(labels)[0]\n",
    "                else:\n",
    "\n",
    "                    # generate a test\n",
    "                    feature_index, self.decision_function = generate_best_test(data_points, skip_features=skip_features)\n",
    "\n",
    "                    # apply the test\n",
    "                    test_passed = np.apply_along_axis(self.decision_function ,axis=1,arr=observations)\n",
    "                    skip_features.append(feature_index)\n",
    "\n",
    "                    # obtain the separated datapoints\n",
    "                    passed_datapoints = D[test_passed,:] \n",
    "                    failed_datapoints = D[np.invert(test_passed),:]\n",
    "\n",
    "#                     print('passed_datapoints:', passed_datapoints)\n",
    "#                     print('failed_datapoints:', failed_datapoints)\n",
    "\n",
    "                    # recursively build nodes.\n",
    "                    self.L = DecisionNode(data_points=passed_datapoints, skip_features=skip_features)\n",
    "                    self.R = DecisionNode(data_points=failed_datapoints, skip_features=skip_features)\n",
    "                    self.details = details\n",
    "                    self.feature_index = feature_index\n",
    "                    self.data_points = data_points\n",
    "            \n",
    "    def classify(self,data_point):\n",
    "        print('Now classifying',data_point)\n",
    "        if self.is_leaf():\n",
    "            return self.label\n",
    "        rule_result = self.decision_function(data_point)\n",
    "        if rule_result == True:\n",
    "            return self.L.classify(data_point)\n",
    "        else:\n",
    "            return self.R.classify(data_point)\n",
    "\n",
    "#     def left_entropy(self):\n",
    "#         return dataset_entropy(self.L.data_points)\n",
    "    \n",
    "#     def right_entropy(self):\n",
    "#         return dataset_entropy(self.R.data_points)\n",
    "\n",
    "        \n",
    "    \n",
    "class DecisionTree(Tree):\n",
    "    def __init__(self, dataset, root):\n",
    "        self.dataset = dataset\n",
    "        self.root = root\n",
    "    @staticmethod\n",
    "    def build_tree(dataset):\n",
    "        return DecisionTree( dataset= dataset, root= DecisionNode(data_points = dataset, skip_features=[]) )\n",
    "    def classify(self, data_point):\n",
    "        return self.root.classify(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 1, 1, 0, 'A'),\n",
       " (5, 1, 0, 1, 'A'),\n",
       " (5, 0, 0, 1, 'A'),\n",
       " (5, 0, 0, 0, 'A'),\n",
       " (3, 0, 0, 0, 'B'),\n",
       " (3, 1, 0, 0, 'B'),\n",
       " (3, 1, 1, 0, 'B'),\n",
       " (3, 1, 1, 1, 'B')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Picked feature', 0, ' with boundary ', '3')\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree.build_tree(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Now classifying', (5, 1, 0, 1, 'A'))\n",
      "('Now classifying', (5, 1, 0, 1, 'A'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.classify(D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Now classifying', ('10', 0, 0, 0))\n",
      "('Now classifying', ('10', 0, 0, 0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.classify(('10',0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
