{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%pylab inline\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataDistribution(object):\n",
    "    def __init__(self, mu=4, sigma=0.5):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    def sample(self, N):\n",
    "        return np.sort(np.random.normal(self.mu, self.sigma, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_d = DataDistribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ12SGmKoS1JDDHVJaoihLkkN+X9XFBqmpVOONwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103d98190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(p_d.sample(1000), bins=50,range=(-6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Noise(object):\n",
    "    def __init__(self, range):\n",
    "        self.range = range\n",
    "    def sample(self, N):\n",
    "        return np.linspace(-self.range, self.range, N) + np.random.normal(N) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(tensor, out_dim, scope=None, stddev=1):\n",
    "    with tf.variable_scope(scope or 'fc'):\n",
    "        # scopes: https://www.tensorflow.org/how_tos/variable_scope/\n",
    "        w = tf.get_variable('w', \\\n",
    "                            shape=(tensor.get_shape()[1], out_dim), \\\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "        b = tf.get_variable('b', \\\n",
    "                            shape=[out_dim], \\\n",
    "                            initializer=tf.constant_initializer(value=0))\n",
    "        return tf.matmul(tensor, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x, hidden_dimensions, activations):\n",
    "    \"\"\"\n",
    "        Creates a generator network. \n",
    "        Note the number of layers in the network will be \n",
    "        len(hidden_dimensions)+1 as the last fully connected layer\n",
    "        doesn't have an activation\n",
    "        \n",
    "        @params:\n",
    "            x: the input tensor\n",
    "            hidden_dimensions: the list of hidden nodes in each layer\n",
    "            activations: the list of activation functions to use in each layer\n",
    "        @returns:\n",
    "            a tensor representing the computation from a neural network\n",
    "            (the dimension of this network out will be 1, representing the p_g)\n",
    "    \"\"\"\n",
    "    assert len(hidden_dimensions) == len(activations), \\\n",
    "    'must have same number of hidden_dimensions as activations'\n",
    "    \n",
    "    previous_layer_result = x\n",
    "    for i, (h, a) in enumerate(zip(hidden_dimensions, activations)):\n",
    "        previous_layer_result = a(fully_connected(previous_layer_result, h, 'g'+str(i)))\n",
    "\n",
    "    return fully_connected(previous_layer_result, 1, 'g_out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, hidden_dimensions, activations):\n",
    "    \"\"\"\n",
    "        Creates a discriminator network.\n",
    "        Note the number of layers in the network will be\n",
    "        len(hidden_dimensions)+1 as the last fully connected layer\n",
    "        has a sigmoid activation function.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(hidden_dimensions) == len(activations), \\\n",
    "    'must have the same number of hidden_dimensions as activations'\n",
    "    \n",
    "    previous_layer_result = x\n",
    "    for i, (h, a) in enumerate(zip(hidden_dimensions, activations)):\n",
    "        previous_layer_result = a(fully_connected(previous_layer_result, h, 'd'+str(i)))\n",
    "    \n",
    "    return tf.sigmoid(fully_connected(previous_layer_result, 1, scope='d_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizer(loss, var_list, lr_0):\n",
    "    decay = 0.95\n",
    "    num_decay_steps = 150\n",
    "    step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        lr_0,\n",
    "        step,\n",
    "        num_decay_steps,\n",
    "        decay,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(\n",
    "        loss,\n",
    "        global_step=step,\n",
    "        var_list=var_list\n",
    "    )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "D_HIDDEN_SIZE = 4\n",
    "D_LAYERS = [ D_HIDDEN_SIZE ] * 3 \n",
    "D_ACTIVATIONS = [ tf.nn.tanh ] * 3\n",
    "G_HIDDEN_SIZE = 4\n",
    "G_LAYERS = [ G_HIDDEN_SIZE ] * 1\n",
    "G_ACTIVATIONS = [ tf.nn.softplus ] * 1\n",
    "LR = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see scope naming here: https://www.tensorflow.org/how_tos/variable_scope/\n",
    "\n",
    "# pretrained D\n",
    "with tf.variable_scope('D_pre'):\n",
    "    # the inputs are of shape b*1\n",
    "    x_pre = tf.placeholder(tf.float32, shape=(BATCH_SIZE, 1))\n",
    "    # outputs are of shape b*1\n",
    "    y_pre = tf.placeholder(tf.float32, shape=(BATCH_SIZE, 1))\n",
    "    D_pre = discriminator(x_pre, D_LAYERS, D_ACTIVATIONS)\n",
    "    D_pre_loss = tf.reduce_mean(tf.square(D_pre - y_pre))\n",
    "    D_pre_optimizer = optimizer(D_pre_loss, None, LR)\n",
    "    \n",
    "with tf.variable_scope('G'):\n",
    "    # random noise of shape b*1\n",
    "    z = tf.placeholder(tf.float32, shape=(BATCH_SIZE, 1))\n",
    "    G = generator(z, G_LAYERS, G_ACTIVATIONS)\n",
    "    \n",
    "with tf.variable_scope('D') as scope:\n",
    "    x = tf.placeholder(tf.float32, shape=(BATCH_SIZE, 1))\n",
    "    \n",
    "    # the network that will classify real data\n",
    "    # D1 = D(x) \n",
    "    D1 = discriminator(x, D_LAYERS, D_ACTIVATIONS)\n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    # the network that will classify the generated data\n",
    "    # D2 = D(G(z))\n",
    "    D2 = discriminator(G, D_LAYERS, D_ACTIVATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the discriminator:\n",
    "# we want D1 to be high and D2 to be low therefore 1-D2 to be high\n",
    "D_loss = tf.reduce_mean(-tf.log(D1) - tf.log(1-D2))\n",
    "\n",
    "# for the generator, the goal is to only fool the discriminator\n",
    "# therefor we want D2 to be high and thus -log(D2) to be low\n",
    "G_loss = tf.reduce_mean(-tf.log(D2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRETRAIN_STEPS = 1000\n",
    "STEPS = 10000\n",
    "N_points = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = tf.trainable_variables()\n",
    "d_pre_params = [v for v in variables if v.name.startswith('D_pre/')]\n",
    "d_params = [v for v in variables if v.name.startswith('D/')]\n",
    "g_params = [v for v in variables if v.name.startswith('G/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_opt = optimizer(D_loss, d_params, LR)\n",
    "G_opt = optimizer(G_loss, g_params, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_d = DataDistribution()\n",
    "p_z = Noise(range=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_samples(p_z, session, G, N_points, BATCH_SIZE):\n",
    "    \"\"\"\n",
    "        Samples from a noise distribution p_z\n",
    "        using a tf.session runs G with z drawn from p_z\n",
    "    \"\"\"\n",
    "    g = np.zeros((N_points, 1))\n",
    "    zs = p_z.sample(1000)\n",
    "   \n",
    "    for i in range(N_points // BATCH_SIZE):\n",
    "        g[BATCH_SIZE*i: BATCH_SIZE*(i+1), :] = session.run(G,{\n",
    "                z: np.reshape(zs[BATCH_SIZE*i:BATCH_SIZE*(i+1)], (BATCH_SIZE,1))\n",
    "            })\n",
    "        \n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining done\n",
      "STEP:0/10000\n",
      "Discriminator Loss: 1.24635\n",
      "Generator Loss:1.95402\n",
      "STEP:100/10000\n",
      "Discriminator Loss: 0.704478\n",
      "Generator Loss:1.86254\n",
      "STEP:200/10000\n",
      "Discriminator Loss: 1.72643\n",
      "Generator Loss:0.7994\n",
      "STEP:300/10000\n",
      "Discriminator Loss: 1.45859\n",
      "Generator Loss:0.614563\n",
      "STEP:400/10000\n",
      "Discriminator Loss: 1.39033\n",
      "Generator Loss:0.683743\n",
      "STEP:500/10000\n",
      "Discriminator Loss: 1.38806\n",
      "Generator Loss:0.690231\n",
      "STEP:600/10000\n",
      "Discriminator Loss: 1.38755\n",
      "Generator Loss:0.691851\n",
      "STEP:700/10000\n",
      "Discriminator Loss: 1.38665\n",
      "Generator Loss:0.692761\n",
      "STEP:800/10000\n",
      "Discriminator Loss: 1.38669\n",
      "Generator Loss:0.692264\n",
      "STEP:900/10000\n",
      "Discriminator Loss: 1.38867\n",
      "Generator Loss:0.692661\n",
      "STEP:1000/10000\n",
      "Discriminator Loss: 1.38662\n",
      "Generator Loss:0.69342\n",
      "STEP:1100/10000\n",
      "Discriminator Loss: 1.38674\n",
      "Generator Loss:0.692362\n",
      "STEP:1200/10000\n",
      "Discriminator Loss: 1.38677\n",
      "Generator Loss:0.693123\n",
      "STEP:1300/10000\n",
      "Discriminator Loss: 1.38683\n",
      "Generator Loss:0.692992\n",
      "STEP:1400/10000\n",
      "Discriminator Loss: 1.38638\n",
      "Generator Loss:0.693541\n",
      "STEP:1500/10000\n",
      "Discriminator Loss: 1.38659\n",
      "Generator Loss:0.693112\n",
      "STEP:1600/10000\n",
      "Discriminator Loss: 1.38653\n",
      "Generator Loss:0.692567\n",
      "STEP:1700/10000\n",
      "Discriminator Loss: 1.387\n",
      "Generator Loss:0.693142\n",
      "STEP:1800/10000\n",
      "Discriminator Loss: 1.38672\n",
      "Generator Loss:0.693094\n",
      "STEP:1900/10000\n",
      "Discriminator Loss: 1.38645\n",
      "Generator Loss:0.693134\n",
      "STEP:2000/10000\n",
      "Discriminator Loss: 1.38651\n",
      "Generator Loss:0.693563\n",
      "STEP:2100/10000\n",
      "Discriminator Loss: 1.38651\n",
      "Generator Loss:0.693714\n",
      "STEP:2200/10000\n",
      "Discriminator Loss: 1.38673\n",
      "Generator Loss:0.692144\n",
      "STEP:2300/10000\n",
      "Discriminator Loss: 1.38657\n",
      "Generator Loss:0.692713\n",
      "STEP:2400/10000\n",
      "Discriminator Loss: 1.386\n",
      "Generator Loss:0.693278\n",
      "STEP:2500/10000\n",
      "Discriminator Loss: 1.3859\n",
      "Generator Loss:0.693233\n",
      "STEP:2600/10000\n",
      "Discriminator Loss: 1.38685\n",
      "Generator Loss:0.692876\n",
      "STEP:2700/10000\n",
      "Discriminator Loss: 1.38666\n",
      "Generator Loss:0.693248\n",
      "STEP:2800/10000\n",
      "Discriminator Loss: 1.38637\n",
      "Generator Loss:0.693372\n",
      "STEP:2900/10000\n",
      "Discriminator Loss: 1.38643\n",
      "Generator Loss:0.693516\n",
      "STEP:3000/10000\n",
      "Discriminator Loss: 1.38651\n",
      "Generator Loss:0.693183\n",
      "STEP:3100/10000\n",
      "Discriminator Loss: 1.38645\n",
      "Generator Loss:0.693365\n",
      "STEP:3200/10000\n",
      "Discriminator Loss: 1.38658\n",
      "Generator Loss:0.692899\n",
      "STEP:3300/10000\n",
      "Discriminator Loss: 1.38641\n",
      "Generator Loss:0.692533\n",
      "STEP:3400/10000\n",
      "Discriminator Loss: 1.38644\n",
      "Generator Loss:0.692638\n",
      "STEP:3500/10000\n",
      "Discriminator Loss: 1.3864\n",
      "Generator Loss:0.692686\n",
      "STEP:3600/10000\n",
      "Discriminator Loss: 1.38624\n",
      "Generator Loss:0.692941\n",
      "STEP:3700/10000\n",
      "Discriminator Loss: 1.38659\n",
      "Generator Loss:0.693059\n",
      "STEP:3800/10000\n",
      "Discriminator Loss: 1.38657\n",
      "Generator Loss:0.69308\n",
      "STEP:3900/10000\n",
      "Discriminator Loss: 1.38623\n",
      "Generator Loss:0.69313\n",
      "STEP:4000/10000\n",
      "Discriminator Loss: 1.38639\n",
      "Generator Loss:0.693063\n",
      "STEP:4100/10000\n",
      "Discriminator Loss: 1.38632\n",
      "Generator Loss:0.69307\n",
      "STEP:4200/10000\n",
      "Discriminator Loss: 1.38647\n",
      "Generator Loss:0.693116\n",
      "STEP:4300/10000\n",
      "Discriminator Loss: 1.38634\n",
      "Generator Loss:0.693142\n",
      "STEP:4400/10000\n",
      "Discriminator Loss: 1.38633\n",
      "Generator Loss:0.693191\n",
      "STEP:4500/10000\n",
      "Discriminator Loss: 1.38631\n",
      "Generator Loss:0.693283\n",
      "STEP:4600/10000\n",
      "Discriminator Loss: 1.38633\n",
      "Generator Loss:0.693363\n",
      "STEP:4700/10000\n",
      "Discriminator Loss: 1.3864\n",
      "Generator Loss:0.693353\n",
      "STEP:4800/10000\n",
      "Discriminator Loss: 1.38636\n",
      "Generator Loss:0.693396\n",
      "STEP:4900/10000\n",
      "Discriminator Loss: 1.38631\n",
      "Generator Loss:0.693417\n",
      "STEP:5000/10000\n",
      "Discriminator Loss: 1.38626\n",
      "Generator Loss:0.693511\n",
      "STEP:5100/10000\n",
      "Discriminator Loss: 1.38631\n",
      "Generator Loss:0.693318\n",
      "STEP:5200/10000\n",
      "Discriminator Loss: 1.38643\n",
      "Generator Loss:0.693135\n",
      "STEP:5300/10000\n",
      "Discriminator Loss: 1.38641\n",
      "Generator Loss:0.693188\n",
      "STEP:5400/10000\n",
      "Discriminator Loss: 1.38629\n",
      "Generator Loss:0.693375\n",
      "STEP:5500/10000\n",
      "Discriminator Loss: 1.38644\n",
      "Generator Loss:0.693117\n",
      "STEP:5600/10000\n",
      "Discriminator Loss: 1.38646\n",
      "Generator Loss:0.693304\n",
      "STEP:5700/10000\n",
      "Discriminator Loss: 1.38635\n",
      "Generator Loss:0.693264\n",
      "STEP:5800/10000\n",
      "Discriminator Loss: 1.38642\n",
      "Generator Loss:0.693135\n",
      "STEP:5900/10000\n",
      "Discriminator Loss: 1.38639\n",
      "Generator Loss:0.693057\n",
      "STEP:6000/10000\n",
      "Discriminator Loss: 1.38641\n",
      "Generator Loss:0.692945\n",
      "STEP:6100/10000\n",
      "Discriminator Loss: 1.38646\n",
      "Generator Loss:0.69287\n",
      "STEP:6200/10000\n",
      "Discriminator Loss: 1.38643\n",
      "Generator Loss:0.69279\n",
      "STEP:6300/10000\n",
      "Discriminator Loss: 1.38648\n",
      "Generator Loss:0.692869\n",
      "STEP:6400/10000\n",
      "Discriminator Loss: 1.38638\n",
      "Generator Loss:0.692769\n",
      "STEP:6500/10000\n",
      "Discriminator Loss: 1.38643\n",
      "Generator Loss:0.692773\n",
      "STEP:6600/10000\n",
      "Discriminator Loss: 1.38633\n",
      "Generator Loss:0.692929\n",
      "STEP:6700/10000\n",
      "Discriminator Loss: 1.38671\n",
      "Generator Loss:0.692734\n",
      "STEP:6800/10000\n",
      "Discriminator Loss: 1.3864\n",
      "Generator Loss:0.692807\n",
      "STEP:6900/10000\n",
      "Discriminator Loss: 1.38637\n",
      "Generator Loss:0.692769\n",
      "STEP:7000/10000\n",
      "Discriminator Loss: 1.38636\n",
      "Generator Loss:0.692815\n",
      "STEP:7100/10000\n",
      "Discriminator Loss: 1.38633\n",
      "Generator Loss:0.692833\n",
      "STEP:7200/10000\n",
      "Discriminator Loss: 1.38629\n",
      "Generator Loss:0.692832\n",
      "STEP:7300/10000\n",
      "Discriminator Loss: 1.3863\n",
      "Generator Loss:0.692806\n",
      "STEP:7400/10000\n",
      "Discriminator Loss: 1.3863\n",
      "Generator Loss:0.692874\n",
      "STEP:7500/10000\n",
      "Discriminator Loss: 1.38624\n",
      "Generator Loss:0.692876\n",
      "STEP:7600/10000\n",
      "Discriminator Loss: 1.3863\n",
      "Generator Loss:0.692912\n",
      "STEP:7700/10000\n",
      "Discriminator Loss: 1.38623\n",
      "Generator Loss:0.692944\n",
      "STEP:7800/10000\n",
      "Discriminator Loss: 1.3863\n",
      "Generator Loss:0.692955\n",
      "STEP:7900/10000\n",
      "Discriminator Loss: 1.38644\n",
      "Generator Loss:0.693015\n",
      "STEP:8000/10000\n",
      "Discriminator Loss: 1.38626\n",
      "Generator Loss:0.693027\n",
      "STEP:8100/10000\n",
      "Discriminator Loss: 1.38631\n",
      "Generator Loss:0.692993\n",
      "STEP:8200/10000\n",
      "Discriminator Loss: 1.38648\n",
      "Generator Loss:0.692992\n",
      "STEP:8300/10000\n",
      "Discriminator Loss: 1.38628\n",
      "Generator Loss:0.693021\n",
      "STEP:8400/10000\n",
      "Discriminator Loss: 1.38643\n",
      "Generator Loss:0.693047\n",
      "STEP:8500/10000\n",
      "Discriminator Loss: 1.38622\n",
      "Generator Loss:0.693031\n",
      "STEP:8600/10000\n",
      "Discriminator Loss: 1.38613\n",
      "Generator Loss:0.69303\n",
      "STEP:8700/10000\n",
      "Discriminator Loss: 1.38626\n",
      "Generator Loss:0.693045\n",
      "STEP:8800/10000\n",
      "Discriminator Loss: 1.38642\n",
      "Generator Loss:0.693065\n",
      "STEP:8900/10000\n",
      "Discriminator Loss: 1.38639\n",
      "Generator Loss:0.693068\n",
      "STEP:9000/10000\n",
      "Discriminator Loss: 1.38769\n",
      "Generator Loss:0.693076\n",
      "STEP:9100/10000\n",
      "Discriminator Loss: 1.38635\n",
      "Generator Loss:0.693089\n",
      "STEP:9200/10000\n",
      "Discriminator Loss: 1.38619\n",
      "Generator Loss:0.693071\n",
      "STEP:9300/10000\n",
      "Discriminator Loss: 1.38621\n",
      "Generator Loss:0.693071\n",
      "STEP:9400/10000\n",
      "Discriminator Loss: 1.3863\n",
      "Generator Loss:0.693088\n",
      "STEP:9500/10000\n",
      "Discriminator Loss: 1.38629\n",
      "Generator Loss:0.693082\n",
      "STEP:9600/10000\n",
      "Discriminator Loss: 1.38625\n",
      "Generator Loss:0.69309\n",
      "STEP:9700/10000\n",
      "Discriminator Loss: 1.38629\n",
      "Generator Loss:0.693094\n",
      "STEP:9800/10000\n",
      "Discriminator Loss: 1.38622\n",
      "Generator Loss:0.693094\n",
      "STEP:9900/10000\n",
      "Discriminator Loss: 1.38618\n",
      "Generator Loss:0.693101\n",
      "TRAINING COMPLETED\n"
     ]
    }
   ],
   "source": [
    "sampled = {}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    sampled[0] = create_samples(p_z, session, G, N_points, BATCH_SIZE)\n",
    "    \n",
    "    # pretraining:\n",
    "    for step in xrange(PRETRAIN_STEPS):\n",
    "        d = (np.random.random(BATCH_SIZE)-0.5) * 10\n",
    "        labels = norm.pdf(d, loc=p_d.mu, scale=p_d.sigma)\n",
    "        pretrain_loss, _ = session.run([D_pre_loss, D_pre_optimizer],{\n",
    "                x_pre : np.reshape(d, (BATCH_SIZE, 1)),\n",
    "                y_pre : np.reshape(labels, (BATCH_SIZE, 1))\n",
    "            })\n",
    "    \n",
    "    sampled[1] = create_samples(p_z, session, G, N_points, BATCH_SIZE)\n",
    "    print('Pretraining done')\n",
    "    weightsD = session.run(d_pre_params)\n",
    "    \n",
    "    # assign the pretrained weights to the new D network\n",
    "    for i, v in enumerate(d_params):\n",
    "        session.run(v.assign(weightsD[i]))\n",
    "    i = 1\n",
    "    for step in xrange(STEPS):\n",
    "        x_ = p_d.sample(BATCH_SIZE).reshape(-1, 1)\n",
    "        z_ = p_z.sample(BATCH_SIZE).reshape(-1, 1)\n",
    "        \n",
    "        loss_d, _ = session.run([D_loss, D_opt], {\n",
    "                x: x_,\n",
    "                z: z_\n",
    "            })\n",
    "        \n",
    "        z_ = p_z.sample(BATCH_SIZE).reshape(-1,1)\n",
    "        \n",
    "        loss_g, _ = session.run([G_loss, G_opt], {\n",
    "                z: z_\n",
    "            })\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            i+=1\n",
    "            print('STEP:'+str(step)+'/'+str(STEPS))\n",
    "            print('Discriminator Loss: '+str(loss_d))\n",
    "            print('Generator Loss:'+str(loss_g))\n",
    "            sampled[i] = create_samples(p_z, session, G, N_points, BATCH_SIZE)\n",
    "    print('TRAINING COMPLETED')\n",
    "    # generate samples:\n",
    "    i+=1\n",
    "    sampled[i] = create_samples(p_z, session, G, N_points, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1096e7410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(sampled[0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZIaYaBLUiMMdElqhIEuSY34/50iwkwDybXDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11023d990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(sampled[102], bins=100)\n",
    "_ = plt.hist(p_d.sample(1000), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
